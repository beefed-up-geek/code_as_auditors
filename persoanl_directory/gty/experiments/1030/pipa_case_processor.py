import json
import os
from pathlib import Path
from typing import Any, Dict, List

from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm


PROMPT_TEMPLATE = """ 
ÏûÖÎ†•ÏúºÎ°ú Ï£ºÏñ¥ÏßÑ ÏÇ¨Í±¥ Î¨∏ÏÑú(Ïã¨Ïùò¬∑ÏùòÍ≤∞ÏÑú Îì±)Î•º ÏùΩÍ≥†, Í∑∏ ÏïàÏóêÏÑú ÎìúÎü¨ÎÇú ÏÇ¨ÏóÖÏûêÏùò Í∞úÏù∏Ï†ïÎ≥¥ Ï≤òÎ¶¨ Î∞©ÏãùÍ≥º 
ÏúÑÎ∞òÎêú Î≤ï Ï°∞Ìï≠ÏùÑ JSON Íµ¨Ï°∞Î°ú Ï†ïÎ¶¨ÌïòÎùº. 

Ï∂úÎ†•ÏùÄ Î∞òÎìúÏãú ÌïòÎÇòÏùò JSON Í∞ùÏ≤¥Ïó¨Ïïº ÌïòÎ©∞, JSONÏùò ÌïÑÎìú ÏàúÏÑúÎäî Îã§ÏùåÍ≥º Í∞ôÏïÑÏïº ÌïúÎã§:

1. case_id: Î¨∏ÏÑúÏóê Î™ÖÏãúÎêú ÏÇ¨Í±¥Î≤àÌò∏ ÎòêÎäî ÏïàÍ±¥Î≤àÌò∏Î•º Í∑∏ÎåÄÎ°ú Í∏∞ÏûÖÌïúÎã§. (Ïòà: "2021-013-103, 2021Ï°∞Ïùº035")
2. business: Ï°∞ÏÇ¨¬∑Ï≤òÎ∂ÑÏùò ÎåÄÏÉÅÏù¥ Îêú Í∏∞ÏóÖÎ™Ö ÎòêÎäî ÏÑúÎπÑÏä§Î™Ö. (Ïòà: "ÎÑ∑ÌîåÎ¶≠Ïä§", "Íµ¨Í∏Ä", "Ïπ¥Ïπ¥Ïò§" Îì±)
3. violated_articles: Í∞Å ÏúÑÎ∞ò Î≤ï Ï°∞Ìï≠Ïùò id(Î≤ï Ï¢ÖÎ•ò & Ï°∞, Ìï≠, Ìò∏, Î™© Îì± ÏÑ∏Î∂Ä ÏúÑÏπò)ÏôÄ reason(Ï°∞Î¨∏Ïùò ÎÇ¥Ïö©, Í∏∞ÏóÖÏùò ÏúÑÎ∞ò ÌñâÏúÑ, ÏúÑÎ∞ò Ïù¥Ïú†)
4. content: Î¨∏ÏÑúÏóêÏÑú ÎìúÎü¨ÎÇú Í∞úÏù∏Ï†ïÎ≥¥ ÏàòÏßë¬∑ÎèôÏùò¬∑Ïù¥Ïö©¬∑Î≥¥Í¥Ä¬∑Ï≤òÎ¶¨¬∑Ïù¥Ï†ÑÏùò Î™®Îì† Í≥ºÏ†ïÏùÑ 
   Í∞ùÍ¥ÄÏ†ÅÏúºÎ°ú Í∏∞Ïà†ÌïòÎêò(ÌäπÌûà ÏúÑÎ∞ò ÏÇ¨Ìï≠Í≥º Í¥ÄÎ†®Îêú Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Îã®Í≥ÑÎì§Ïù¥ Í∞ïÏ°∞ ÎêòÏïºÌï®), Î≤ï ÏúÑÎ∞ò Ïó¨Î∂ÄÎÇò Î≤ïÍ≥º Í¥ÄÎ†®Îêú ÎÇ¥Ïö©ÏùÑ Ïñ∏Í∏âÌïòÏßÄ ÏïäÎäîÎã§.

Ï∂úÎ†• ÌòïÏãù ÏòàÏãúÎäî Îã§ÏùåÍ≥º Í∞ôÎã§:

{
  "case_id": "2021-013-103",
  "business": "ÎÑ∑ÌîåÎ¶≠Ïä§",
  "violated_articles": [
    { "id": {"law": "Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏Î≤ï", "id": "Ï†ú39Ï°∞Ïùò12 Ï†ú2Ìï≠"}, "reason": "..." },
    { "id": {"law": "ÏãúÌñâÎ†π", "id": "Ï†ú30Ï°∞ Ï†ú2Ìï≠ Ï†ú4Ìò∏"}, "reason": "..." },
    { "id": {"law": "Ï†ïÎ≥¥ÌÜµÏã†ÎßùÎ≤ï", "id": "Ï†ú28Ï°∞ Ï†ú1Ìï≠"}, "reason": "..." },
  ],
  "content": "..."
}

Ï£ºÏùòÏÇ¨Ìï≠:
- Î∞òÎìúÏãú JSONÎßå Ï∂úÎ†•ÌïòÍ≥†, Îã§Î•∏ ÏÑ§Î™ÖÎ¨∏Ïù¥ÎÇò Ìï¥ÏÑ§ÏùÑ ÎçßÎ∂ôÏù¥ÏßÄ ÏïäÎäîÎã§.
- case_idÏôÄ businessÎäî Î¨∏ÏÑúÏóêÏÑú ÏßÅÏ†ë Ï∂îÏ∂ú Í∞ÄÎä•Ìïú Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú ÏûëÏÑ±ÌïúÎã§.
- violated_articles ÏïàÏóêÎäî ÏïÑÎûòÏùò ÏÇ¨Í±¥ Î¨∏ÏÑúÏóêÏÑú ÏúÑÎ≤ïÏù¥ÎùºÍ≥† Ï†ïÌôïÌûà ÌåêÎ≥ÑÌïú Î≤ïÎ•† Ï°∞Ìï≠Îì§ÏùÑ Ï§ëÎ≥µ ÏóÜÏù¥ Î™®Îëê Ìè¨Ìï®Ìï¥ÏïºÌïúÎã§. 
- violated_articles ÏïàÏùò lawÏóêÎäî "Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏Î≤ï", "ÏãúÌñâÎ†π" ÎòêÎäî Í∏∞ÌÉÄ Î≤ïÏùò Ï¢ÖÎ•òÎ•º Î™ÖÏãúÌïúÎã§.  
- violated_articles ÏïàÏùò id Îì§ÏùÄ Í∞ÄÎä•Ìïú Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Î™ÖÏãúÌïúÎã§. ÎòêÌïú Ï°∞, Ìï≠, Ìò∏ Î™©ÏùÑ ÌòïÏãùÏóê ÎßûÍ≤å ÌëúÏãúÌïúÎã§. (ex.Ï†ú3Ï°∞, Ï†ú4Ï°∞Ïùò2 Ï†ú1Ìï≠, Ï†ú5Ï°∞ Ï†ú7Ìï≠, Ï†ú3Î™©) 
- reasonÏùÄ Ï°∞Î¨∏Ïùò ÎÇ¥Ïö©, Í∏∞ÏóÖÏùò ÏúÑÎ∞ò ÌñâÏúÑ, ÏúÑÎ∞ò Ïù¥Ïú†Î•º Ïó∞Í≤∞ÌïòÏó¨ Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† ÎÖºÎ¶¨Ï†ÅÏù¥Í≤å Í∏∞Ïà†ÌïúÎã§. 
- contentÏóêÎäî ÏÇ¨ÏóÖÏûêÏùò Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞©Ïãù(ÏàòÏßë Ìï≠Î™©, Î™©Ï†Å, ÏãúÏ†ê, Î≥¥Í¥Ä Í∏∞Í∞Ñ, Íµ≠Ïô∏ Ïù¥Ï†Ñ, ÏãúÏä§ÌÖú Íµ¨Ï°∞ Îì±)ÏùÑ ÏµúÎåÄÌïú Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Ìè¨Ìï®ÌïúÎã§.
- contentÏóêÎäî ‚ÄúÏúÑÎ∞ò‚Äù, ‚ÄúÎ∂àÎ≤ï‚Äù, ‚ÄúÏúÑÎ≤ïÌïòÎã§‚Äù Îì±Ïùò ÌëúÌòÑÍ≥º Î≤ïÏóê ÎåÄÌïú Ïñ¥Îñ§ Ïñ∏Í∏âÎèÑ Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎäîÎã§.
- ÌïòÏßÄÎßå, Ï§ëÏöîÌïú Ï†êÏùÄ contentÏóêÎäî violated_articlesÏóê Î™ÖÏãúÎêú Í∏∞ÏóÖÏùò ÏúÑÎ∞ò ÌñâÏúÑÎì§Ïù¥ ÎàÑÎùΩ ÏóÜÏù¥ Í∞ïÏ°∞ÎêòÏñ¥ Îì§Ïñ¥Í∞ÄÏûàÏñ¥ÏïºÌïúÎã§. 

ÏïÑÎûòÎäî Î∂ÑÏÑùÌï† ÏÇ¨Í±¥ Î¨∏ÏÑúÏùò Ï†ÑÎ¨∏Ïù¥Îã§. 
Ïù¥ Î¨∏ÏÑúÏùò ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏúÑ ÏßÄÏπ®Ïóê Îî∞Îùº Ïò§ÏßÅ JSONÎßåÏùÑ Î∞òÌôòÌïòÎùº.

------ ÏÇ¨Í±¥ Î¨∏ÏÑú ÏãúÏûë ------
{document}
------ ÏÇ¨Í±¥ Î¨∏ÏÑú ÎÅù ------
"""


def extract_output_text(response: Any) -> str:
    """Extract plain text from responses API result."""
    response_text = getattr(response, "output_text", None)

    if response_text:
        return response_text.strip()

    if hasattr(response, "model_dump"):
        response_payload = response.model_dump()
    elif isinstance(response, dict):
        response_payload = response
    else:
        response_payload = {}

    response_text = response_payload.get("output_text")
    if isinstance(response_text, str) and response_text.strip():
        return response_text.strip()

    output_items = response_payload.get("output") if isinstance(response_payload, dict) else None
    if output_items is None:
        output_items = getattr(response, "output", []) or []

    segments: List[str] = []
    for item in output_items:
        if isinstance(item, dict):
            content_list = item.get("content", [])
        else:
            content_list = getattr(item, "content", []) or []

        for segment in content_list:
            if isinstance(segment, dict):
                text_value = segment.get("text")
            else:
                text_value = getattr(segment, "text", None)
            if text_value:
                segments.append(text_value)

    return "".join(segments).strip()


def refine_json_with_agent(client: OpenAI, raw_text: str, relative_path: str) -> Dict[str, Any]:
    """Use chat completions JSON mode to clean up malformed JSON."""
    print(f"üîÅ Retrying JSON parsing for {relative_path} via gpt-4o JSON agent.")
    messages = [
        {
            "role": "system",
            "content": "You are a JSON formatting assistant. Return valid JSON only with the same fields requested originally.",
        },
        {
            "role": "user",
            "content": (
                "Îã§Ïùå ÌÖçÏä§Ìä∏Îäî Í∞úÏù∏Ï†ïÎ≥¥ ÏÇ¨Í±¥ Î∂ÑÏÑù Í≤∞Í≥ºÏßÄÎßå JSON ÌòïÏãùÏóê Ïò§Î•òÍ∞Ä ÏûàÏäµÎãàÎã§. "
                "ÏõêÎûòÏùò ÌïÑÎìúÏôÄ Íµ¨Ï°∞(case_id, business, violated_articles(json Î¶¨Ïä§Ìä∏ ÎÇ¥Ïö© Ïú†ÏßÄ), content)Î•º Ïú†ÏßÄÌïòÎ©¥ÏÑú Ïú†Ìö®Ìïú JSON Í∞ùÏ≤¥Î°ú Ï†ïÏ†úÌï¥ Ï£ºÏÑ∏Ïöî. "
                "JSON Ïô∏Ïùò Îã§Î•∏ ÏÑ§Î™ÖÏùÄ Ï∂îÍ∞ÄÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n\n"
                "----- ÏõêÎ≥∏ ÌÖçÏä§Ìä∏ -----\n"
                f"{raw_text}\n"
                "----- ÎÅù -----"
            ),
        },
    ]

    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        response_format={"type": "json_object"},
    )

    fixed_text = completion.choices[0].message.content
    if not fixed_text:
        raise ValueError("JSON parsing agent returned empty output.")

    try:
        return json.loads(fixed_text)
    except json.JSONDecodeError as exc:
        raise ValueError("JSON parsing agent returned invalid JSON.") from exc


def load_existing_results(output_path: Path) -> List[Dict[str, Any]]:
    if not output_path.exists():
        return []
    try:
        with output_path.open("r", encoding="utf-8") as file:
            data = json.load(file)
            if isinstance(data, list):
                return data
    except json.JSONDecodeError:
        pass
    return []


def ensure_processed_paths(results: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
    processed: Dict[str, Dict[str, Any]] = {}
    for item in results:
        source_path = item.get("source_path")
        if isinstance(source_path, str):
            processed[source_path] = item
    return processed


def build_prompt(document_text: str) -> str:
    """PROMPT_TEMPLATEÏóê Î¨∏ÏÑú ÏÇΩÏûÖ"""
    return PROMPT_TEMPLATE.replace("{document}", document_text)


def main() -> None:
    load_dotenv()
    if not os.getenv("OPENAI_API_KEY"):
        raise EnvironmentError("OPENAI_API_KEY is not set. Check your .env file.")

    base_dir = Path("/Users/taeyoonkwack/Documents/code_as_auditors/dataset/PIPA/cases/original")
    output_path = Path("/Users/taeyoonkwack/Documents/code_as_auditors/persoanl_directory/gty/experiments/1030/pipa_cases_analysis.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    existing_results = load_existing_results(output_path)
    processed_map = ensure_processed_paths(existing_results)

    all_txt_files = sorted(base_dir.rglob("*.txt"))
    client = OpenAI()
    aggregated_results = existing_results[:]

    for txt_file in tqdm(all_txt_files, desc="Processing case files"):
        relative_path = str(txt_file.relative_to(base_dir))
        if relative_path in processed_map:
            continue

        try:
            document_text = txt_file.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            document_text = txt_file.read_text(encoding="utf-8", errors="replace")

        prompt = build_prompt(document_text)

        # ‚úÖ ÏïàÏ†ïÏ†Å: responses API Í∏∞Î∞ò Ìò∏Ï∂ú
        try:
            response = client.responses.create(
                model="gpt-5",
                input=prompt,
                reasoning={"effort": "low"},
                #response_format={"type": "json_object"},
            )

            response_text = extract_output_text(response)
            if not response_text:
                raise ValueError("Model returned empty output.")

            try:
                analysis = json.loads(response_text)
            except json.JSONDecodeError:
                analysis = refine_json_with_agent(client, response_text, relative_path)

        except Exception as e:
            print(f"‚ùå Error processing {relative_path}: {e}")
            continue

        result_entry = {
            "source_path": relative_path,
            "analysis": analysis,
        }

        aggregated_results.append(result_entry)
        processed_map[relative_path] = result_entry

        # Ï§ëÍ∞Ñ Ï†ÄÏû•
        with output_path.open("w", encoding="utf-8") as file:
            json.dump(aggregated_results, file, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    main()
